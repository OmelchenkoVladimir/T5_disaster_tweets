{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import T5Tokenizer, T5Model, T5ForConditionalGeneration\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "pd.set_option('display.max_colwidth', 4000)\n",
    "DEBUG = False # !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of T5ForConditionalGeneration were not initialized from the model checkpoint at t5-base and are newly initialized: ['encoder.embed_tokens.weight', 'decoder.embed_tokens.weight', 'lm_head.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "tok = T5Tokenizer.from_pretrained('t5-base') # large = out of memory on optim.step()\n",
    "mdl = T5ForConditionalGeneration.from_pretrained('t5-base').to('cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/vladimir/anaconda3/envs/t5/lib/python3.8/site-packages/IPython/core/interactiveshell.py:3071: DtypeWarning: Columns (3) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n"
     ]
    }
   ],
   "source": [
    "train_df = pd.read_csv('tweets_data/disaster_response_messages_training.csv')[['message', 'related']]\n",
    "if DEBUG:\n",
    "    train_df = train_df.sample(frac=0.1)\n",
    "valid_df = pd.read_csv('tweets_data/disaster_response_messages_validation.csv')[['message', 'related']]\n",
    "if DEBUG:\n",
    "    valid_df = valid_df.sample(frac=0.1)\n",
    "test_df = pd.read_csv('tweets_data/disaster_response_messages_test.csv')[['message', 'related']]\n",
    "if DEBUG:\n",
    "    test_df = test_df.sample(frac=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    15795\n",
       "0     5083\n",
       "2      168\n",
       "Name: related, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df['related'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#valid_df[valid_df['related']==1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "prefix = 'is_disaster: '\n",
    "suffix = ' </s>'\n",
    "\n",
    "train_df['message'] = train_df['message'].apply(lambda x: prefix + x + suffix)\n",
    "valid_df['message'] = valid_df['message'].apply(lambda x: prefix + x + suffix)\n",
    "test_df['message'] = test_df['message'].apply(lambda x: prefix + x + suffix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ls = train_df['message'].tolist()\n",
    "train_vals = train_df['related'].apply(lambda x: str(x) + suffix).tolist()\n",
    "valid_ls = valid_df['message'].tolist()\n",
    "valid_vals = valid_df['related'].apply(lambda x: str(x) + suffix).tolist()\n",
    "test_ls = test_df['message'].tolist()\n",
    "test_vals = test_df['related'].apply(lambda x: str(x) + suffix).tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TweetsDataset(Dataset):\n",
    "    \n",
    "    def __init__(self, input_ids, attention_mask, decoder_ids, decoder_attention_mask):\n",
    "        assert input_ids.shape == attention_mask.shape\n",
    "        assert decoder_ids.shape == decoder_attention_mask.shape\n",
    "        self.input_ids = input_ids\n",
    "        self.attention_mask = attention_mask\n",
    "        self.decoder_ids = decoder_ids\n",
    "        self.decoder_attention_mask = decoder_attention_mask\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        return (self.input_ids[index], self.attention_mask[index], self.decoder_ids[index], self.decoder_attention_mask[index])\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.input_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dict = tok(train_ls, max_length=512, truncation=True, padding=True, return_tensors='pt')\n",
    "train_label_dict = tok(train_vals, return_tensors='pt', padding=True, truncation=True)\n",
    "\n",
    "train_input_ids = train_dict['input_ids']\n",
    "train_attention_mask = train_dict['attention_mask']\n",
    "train_decoder_ids = train_label_dict['input_ids']\n",
    "train_decoder_attention_mask = train_label_dict['attention_mask']\n",
    "\n",
    "train_dataset = TweetsDataset(train_input_ids, train_attention_mask, train_decoder_ids, train_decoder_attention_mask)\n",
    "train_dl = DataLoader(train_dataset, batch_size=8, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "End of epoch 1\n",
      "CPU times: user 58min 31s, sys: 4min 59s, total: 1h 3min 31s\n",
      "Wall time: 22min 21s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "optim = torch.optim.Adam(mdl.parameters())\n",
    "\n",
    "for epoch in [1]:\n",
    "    for input_ids, attention_mask, decoder_ids, decoder_attention_mask in train_dl:\n",
    "        #print(input_ids.shape, attention_mask.shape)\n",
    "        optim.zero_grad()\n",
    "        # delete attention mask? attention_mask=attention_mask.to('cuda'), \n",
    "        res = mdl(input_ids.to('cuda'), labels=decoder_ids.to('cuda')) #decoder_input_ids=decoder_ids.to('cuda'), decoder_attention_mask=decoder_attention_mask.to('cuda'))\n",
    "        loss = res[0]\n",
    "        loss.backward()\n",
    "        optim.step()\n",
    "        #break;\n",
    "    print(f'End of epoch {epoch}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train_df['message'].apply(lambda x: len(x)).describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_dict = tok(valid_ls, max_length=512, truncation=True, padding=True, return_tensors='pt')\n",
    "valid_label_dict = tok(valid_vals, return_tensors='pt', padding=True, truncation=True)\n",
    "\n",
    "valid_input_ids = valid_dict['input_ids']\n",
    "valid_attention_mask = valid_dict['attention_mask']\n",
    "valid_decoder_ids = valid_label_dict['input_ids']\n",
    "valid_decoder_attention_mask = valid_label_dict['attention_mask']\n",
    "\n",
    "valid_dataset = TweetsDataset(valid_input_ids, valid_attention_mask, valid_decoder_ids, valid_decoder_attention_mask)\n",
    "valid_dl = DataLoader(valid_dataset, batch_size=8, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([8, 3])\n",
      "torch.Size([8, 4])\n",
      "torch.Size([8, 4])\n",
      "torch.Size([8, 4])\n",
      "torch.Size([8, 4])\n",
      "torch.Size([8, 3])\n",
      "torch.Size([8, 4])\n",
      "torch.Size([8, 4])\n",
      "torch.Size([8, 4])\n",
      "torch.Size([8, 4])\n",
      "torch.Size([8, 4])\n",
      "torch.Size([8, 4])\n",
      "torch.Size([8, 4])\n",
      "torch.Size([8, 3])\n",
      "torch.Size([8, 4])\n",
      "torch.Size([8, 4])\n",
      "torch.Size([8, 3])\n",
      "torch.Size([8, 4])\n",
      "torch.Size([8, 4])\n",
      "torch.Size([8, 4])\n",
      "torch.Size([8, 4])\n",
      "torch.Size([8, 4])\n",
      "torch.Size([8, 4])\n",
      "torch.Size([8, 4])\n",
      "torch.Size([8, 4])\n",
      "torch.Size([8, 4])\n",
      "torch.Size([8, 4])\n",
      "torch.Size([8, 4])\n",
      "torch.Size([8, 3])\n",
      "torch.Size([8, 4])\n",
      "torch.Size([8, 3])\n",
      "torch.Size([8, 4])\n",
      "torch.Size([8, 4])\n",
      "torch.Size([8, 4])\n",
      "torch.Size([8, 4])\n",
      "torch.Size([8, 3])\n",
      "torch.Size([8, 4])\n",
      "torch.Size([8, 4])\n",
      "torch.Size([8, 4])\n",
      "torch.Size([8, 4])\n",
      "torch.Size([8, 4])\n",
      "torch.Size([8, 4])\n",
      "torch.Size([8, 3])\n",
      "torch.Size([8, 4])\n",
      "torch.Size([8, 4])\n",
      "torch.Size([8, 4])\n",
      "torch.Size([8, 4])\n",
      "torch.Size([8, 4])\n",
      "torch.Size([8, 4])\n",
      "torch.Size([8, 4])\n",
      "torch.Size([8, 4])\n",
      "torch.Size([8, 3])\n",
      "torch.Size([8, 4])\n",
      "torch.Size([8, 4])\n",
      "torch.Size([8, 3])\n",
      "torch.Size([8, 4])\n",
      "torch.Size([8, 4])\n",
      "torch.Size([8, 4])\n",
      "torch.Size([8, 4])\n",
      "torch.Size([8, 4])\n",
      "torch.Size([8, 4])\n",
      "torch.Size([8, 4])\n",
      "torch.Size([8, 4])\n",
      "torch.Size([8, 4])\n",
      "torch.Size([8, 4])\n",
      "torch.Size([8, 4])\n",
      "torch.Size([8, 4])\n",
      "torch.Size([8, 4])\n",
      "torch.Size([8, 4])\n",
      "torch.Size([8, 4])\n",
      "torch.Size([8, 4])\n",
      "torch.Size([8, 4])\n",
      "torch.Size([8, 3])\n",
      "torch.Size([8, 4])\n",
      "torch.Size([8, 3])\n",
      "torch.Size([8, 4])\n",
      "torch.Size([8, 4])\n",
      "torch.Size([8, 4])\n",
      "torch.Size([8, 3])\n",
      "torch.Size([8, 4])\n",
      "torch.Size([8, 4])\n",
      "torch.Size([8, 4])\n",
      "torch.Size([8, 4])\n",
      "torch.Size([8, 3])\n",
      "torch.Size([8, 4])\n",
      "torch.Size([8, 4])\n",
      "torch.Size([8, 4])\n",
      "torch.Size([8, 4])\n",
      "torch.Size([8, 4])\n",
      "torch.Size([8, 4])\n",
      "torch.Size([8, 3])\n",
      "torch.Size([8, 3])\n",
      "torch.Size([8, 4])\n",
      "torch.Size([8, 3])\n",
      "torch.Size([8, 4])\n",
      "torch.Size([8, 4])\n",
      "torch.Size([8, 4])\n",
      "torch.Size([8, 4])\n",
      "torch.Size([8, 4])\n",
      "torch.Size([8, 4])\n",
      "torch.Size([8, 4])\n",
      "torch.Size([8, 4])\n",
      "torch.Size([8, 4])\n",
      "torch.Size([8, 4])\n",
      "torch.Size([8, 4])\n",
      "torch.Size([8, 3])\n",
      "torch.Size([8, 3])\n",
      "torch.Size([8, 4])\n",
      "torch.Size([8, 4])\n",
      "torch.Size([8, 4])\n",
      "torch.Size([8, 4])\n",
      "torch.Size([8, 4])\n",
      "torch.Size([8, 4])\n",
      "torch.Size([8, 3])\n",
      "torch.Size([8, 4])\n",
      "torch.Size([8, 3])\n",
      "torch.Size([8, 4])\n",
      "torch.Size([8, 4])\n",
      "torch.Size([8, 4])\n",
      "torch.Size([8, 4])\n",
      "torch.Size([8, 4])\n",
      "torch.Size([8, 4])\n",
      "torch.Size([8, 4])\n",
      "torch.Size([8, 4])\n",
      "torch.Size([8, 4])\n",
      "torch.Size([8, 4])\n",
      "torch.Size([8, 3])\n",
      "torch.Size([8, 4])\n",
      "torch.Size([8, 4])\n",
      "torch.Size([8, 4])\n",
      "torch.Size([8, 4])\n",
      "torch.Size([8, 3])\n",
      "torch.Size([8, 4])\n",
      "torch.Size([8, 4])\n",
      "torch.Size([8, 4])\n",
      "torch.Size([8, 4])\n",
      "torch.Size([8, 4])\n",
      "torch.Size([8, 4])\n",
      "torch.Size([8, 4])\n",
      "torch.Size([8, 4])\n",
      "torch.Size([8, 4])\n",
      "torch.Size([8, 3])\n",
      "torch.Size([8, 4])\n",
      "torch.Size([8, 3])\n",
      "torch.Size([8, 4])\n",
      "torch.Size([8, 4])\n",
      "torch.Size([8, 4])\n",
      "torch.Size([8, 4])\n",
      "torch.Size([8, 4])\n",
      "torch.Size([8, 4])\n",
      "torch.Size([8, 4])\n",
      "torch.Size([8, 3])\n",
      "torch.Size([8, 3])\n",
      "torch.Size([8, 4])\n",
      "torch.Size([8, 3])\n",
      "torch.Size([8, 4])\n",
      "torch.Size([8, 4])\n",
      "torch.Size([8, 4])\n",
      "torch.Size([8, 4])\n",
      "torch.Size([8, 4])\n",
      "torch.Size([8, 4])\n",
      "torch.Size([8, 4])\n",
      "torch.Size([8, 4])\n",
      "torch.Size([8, 4])\n",
      "torch.Size([8, 4])\n",
      "torch.Size([8, 4])\n",
      "torch.Size([8, 4])\n",
      "torch.Size([8, 3])\n",
      "torch.Size([8, 4])\n",
      "torch.Size([8, 4])\n",
      "torch.Size([8, 4])\n",
      "torch.Size([8, 4])\n",
      "torch.Size([8, 4])\n",
      "torch.Size([8, 4])\n",
      "torch.Size([8, 4])\n",
      "torch.Size([8, 4])\n",
      "torch.Size([8, 3])\n",
      "torch.Size([8, 4])\n",
      "torch.Size([8, 4])\n",
      "torch.Size([8, 4])\n",
      "torch.Size([8, 4])\n",
      "torch.Size([8, 4])\n",
      "torch.Size([8, 4])\n",
      "torch.Size([8, 4])\n",
      "torch.Size([8, 3])\n",
      "torch.Size([8, 4])\n",
      "torch.Size([8, 4])\n",
      "torch.Size([8, 4])\n",
      "torch.Size([8, 4])\n",
      "torch.Size([8, 4])\n",
      "torch.Size([8, 4])\n",
      "torch.Size([8, 4])\n",
      "torch.Size([8, 4])\n",
      "torch.Size([8, 4])\n",
      "torch.Size([8, 4])\n",
      "torch.Size([8, 3])\n",
      "torch.Size([8, 4])\n",
      "torch.Size([8, 3])\n",
      "torch.Size([8, 4])\n",
      "torch.Size([8, 4])\n",
      "torch.Size([8, 4])\n",
      "torch.Size([8, 4])\n",
      "torch.Size([8, 4])\n",
      "torch.Size([8, 4])\n",
      "torch.Size([8, 4])\n",
      "torch.Size([8, 4])\n",
      "torch.Size([8, 4])\n",
      "torch.Size([8, 4])\n",
      "torch.Size([8, 4])\n",
      "torch.Size([8, 4])\n",
      "torch.Size([8, 4])\n",
      "torch.Size([8, 3])\n",
      "torch.Size([8, 4])\n",
      "torch.Size([8, 4])\n",
      "torch.Size([8, 3])\n",
      "torch.Size([8, 4])\n",
      "torch.Size([8, 4])\n",
      "torch.Size([8, 4])\n",
      "torch.Size([8, 3])\n",
      "torch.Size([8, 4])\n",
      "torch.Size([8, 3])\n",
      "torch.Size([8, 4])\n",
      "torch.Size([8, 4])\n",
      "torch.Size([8, 4])\n",
      "torch.Size([8, 4])\n",
      "torch.Size([8, 4])\n",
      "torch.Size([8, 3])\n",
      "torch.Size([8, 3])\n",
      "torch.Size([8, 4])\n",
      "torch.Size([8, 4])\n",
      "torch.Size([8, 4])\n",
      "torch.Size([8, 4])\n",
      "torch.Size([8, 4])\n",
      "torch.Size([8, 4])\n",
      "torch.Size([8, 4])\n",
      "torch.Size([8, 4])\n",
      "torch.Size([8, 4])\n",
      "torch.Size([8, 4])\n",
      "torch.Size([8, 4])\n",
      "torch.Size([8, 4])\n",
      "torch.Size([8, 4])\n",
      "torch.Size([8, 4])\n",
      "torch.Size([8, 4])\n",
      "torch.Size([8, 3])\n",
      "torch.Size([8, 4])\n",
      "torch.Size([8, 3])\n",
      "torch.Size([8, 4])\n",
      "torch.Size([8, 3])\n",
      "torch.Size([8, 4])\n",
      "torch.Size([8, 4])\n",
      "torch.Size([8, 4])\n",
      "torch.Size([8, 4])\n",
      "torch.Size([8, 4])\n",
      "torch.Size([8, 4])\n",
      "torch.Size([8, 4])\n",
      "torch.Size([8, 4])\n",
      "torch.Size([8, 4])\n",
      "torch.Size([8, 4])\n",
      "torch.Size([8, 4])\n",
      "torch.Size([8, 4])\n",
      "torch.Size([8, 4])\n",
      "torch.Size([8, 4])\n",
      "torch.Size([8, 3])\n",
      "torch.Size([8, 4])\n",
      "torch.Size([8, 4])\n",
      "torch.Size([8, 4])\n",
      "torch.Size([8, 4])\n",
      "torch.Size([8, 4])\n",
      "torch.Size([8, 4])\n",
      "torch.Size([8, 4])\n",
      "torch.Size([8, 4])\n",
      "torch.Size([8, 4])\n",
      "torch.Size([8, 4])\n",
      "torch.Size([8, 4])\n",
      "torch.Size([8, 4])\n",
      "torch.Size([8, 4])\n",
      "torch.Size([8, 4])\n",
      "torch.Size([8, 4])\n",
      "torch.Size([8, 4])\n",
      "torch.Size([8, 4])\n",
      "torch.Size([8, 4])\n",
      "torch.Size([8, 4])\n",
      "torch.Size([8, 4])\n",
      "torch.Size([8, 4])\n",
      "torch.Size([8, 3])\n",
      "torch.Size([8, 4])\n",
      "torch.Size([8, 4])\n",
      "torch.Size([8, 4])\n",
      "torch.Size([8, 3])\n",
      "torch.Size([8, 4])\n",
      "torch.Size([8, 4])\n",
      "torch.Size([8, 4])\n",
      "torch.Size([8, 4])\n",
      "torch.Size([8, 4])\n",
      "torch.Size([8, 4])\n",
      "torch.Size([8, 3])\n",
      "torch.Size([8, 4])\n",
      "torch.Size([8, 3])\n",
      "torch.Size([8, 4])\n",
      "torch.Size([8, 4])\n",
      "torch.Size([8, 4])\n",
      "torch.Size([8, 3])\n",
      "torch.Size([8, 4])\n",
      "torch.Size([8, 4])\n",
      "torch.Size([8, 4])\n",
      "torch.Size([8, 4])\n",
      "torch.Size([8, 4])\n",
      "torch.Size([8, 4])\n",
      "torch.Size([8, 4])\n",
      "torch.Size([8, 4])\n",
      "torch.Size([8, 4])\n",
      "torch.Size([8, 4])\n",
      "torch.Size([8, 4])\n",
      "torch.Size([8, 4])\n",
      "torch.Size([8, 4])\n",
      "torch.Size([8, 4])\n",
      "torch.Size([8, 3])\n",
      "torch.Size([8, 3])\n",
      "torch.Size([8, 4])\n",
      "torch.Size([8, 4])\n",
      "torch.Size([8, 3])\n",
      "torch.Size([5, 4])\n"
     ]
    }
   ],
   "source": [
    "mdl.eval()\n",
    "\n",
    "y = []\n",
    "y_pred = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for input_ids, attention_mask, correct_labels, _ in valid_dl:\n",
    "        res = mdl.generate(input_ids=input_ids.to('cuda'), attention_mask=attention_mask.to('cuda'))\n",
    "        for elem, lbl in zip(res, correct_labels):\n",
    "            y_pred.append(int(tok.decode(elem)))\n",
    "            y.append(int(tok.decode(lbl)))\n",
    "        print(res.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'0'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tok.decode(res[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#mdl.forward?\n",
    "#torch.save(mdl.state_dict(), 'models/mdl_first_try.pkl--')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = np.array(y)\n",
    "y_pred = np.array(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True     2137\n",
       "False     436\n",
       "dtype: int64"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(y==y_pred).value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
